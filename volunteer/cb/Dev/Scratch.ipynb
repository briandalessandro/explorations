{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#These are features we'll exclude, as they're not useful for generalization, and they're specific to the data set used in summer 2019 developing\n",
    "non_model_features = ['start','submission_time','end','device_id','country','developer_code', \n",
    "                      'village_code', 'joint_code', 'gps_coordinates',\n",
    "                       'gps_coordinates_latitude', 'gps_coordinates_longitude',\n",
    "                       'gps_coordinates_altitude', 'gps_coordinates_precision',\n",
    "                       'meter_number','survey_version','meta_instanceid', 'id', 'uuid', 'index', \n",
    "                       'parent_index', 'customer_id','start_date','end_date','tariff_min','tariff_max']\n",
    "\n",
    "\n",
    "def evaluate_regression(predictions, labels):\n",
    "    errors = abs(predictions - labels)\n",
    "    print('MAE', mean_absolute_error(predictions, labels))\n",
    "    print('MSE', mean_squared_error(predictions, labels))\n",
    "    print('R2', r2_score(labels, predictions))\n",
    "    print('Average Error: ', np.mean(errors), 'kwh')\n",
    "\n",
    "def cap_outlier(df, col, max_threshold):\n",
    "    '''\n",
    "    Caps the specified column at the max_threshold \n",
    "    '''\n",
    "    df.loc[df[col]>max_threshold, col] = max_threshold\n",
    "    return df\n",
    "\n",
    "def train_test_split(df, test_pct, random_state=1):\n",
    "    '''\n",
    "    My own train_test_split helper function - keeps target in same DF\n",
    "    '''\n",
    "    model_df_shuf = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    #Data is shuffled so we can just take bottom 10% for test set\n",
    "    test_pct = 0.1\n",
    "    test_index = int(model_df_shuf.shape[0]) * test_pct\n",
    "    test_df = model_df_shuf.loc[:test_index]\n",
    "    train_df = model_df_shuf.loc[test_index:]\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "class FeatureImportanceSummary(object):\n",
    "    '''\n",
    "    Takes in a data frame, features to drop, target_variable\n",
    "    \n",
    "        Builds a RF to compute feature importance scores, also does linear regression to get coefficients and signs\n",
    "    \n",
    "        Produces a dataFrame with the feature importance summary\n",
    "        Gives indices within the dataframe at different thresholds of feature importance\n",
    "    '''\n",
    "    def __init__(self, df, non_model_features, Y):    \n",
    "        self.df = df\n",
    "        self.non_model_features = non_model_features #Features that shouldn't be in a model\n",
    "        self.Y = Y #Target variables\n",
    "        self.feat_imp_df = None\n",
    "        self.feat_imp_thresholds = [0.25, 0.5, 0.8, 0.9, 0.95, 0.99] #thresholds for normalized feature importance\n",
    "        self.feat_imp_index = {}\n",
    "\n",
    "    def get_feature_importance_summary(self):\n",
    "\n",
    "        model_train = self.df.drop(non_model_features, axis=1).copy()\n",
    "\n",
    "        #Fit RF model to get its feature importances\n",
    "        rf = RandomForestRegressor(n_estimators=500, max_depth=10, min_samples_split=5)\n",
    "        rf.fit(model_train.drop(self.Y,axis=1), model_train[self.Y])\n",
    "\n",
    "        #Add to DF\n",
    "        self.feat_imp_df = pd.DataFrame({'x':model_train.drop(self.Y,axis=1).columns.values,'imp':rf.feature_importances_})\n",
    "        self.feat_imp_df = self.feat_imp_df.sort_values(by=['imp'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "        #Get sign of relationship from univariate linear regressions\n",
    "        xs = self.feat_imp_df.x.values\n",
    "\n",
    "        betas = []\n",
    "        signs = []\n",
    "\n",
    "        for x in xs:\n",
    "            beta = LinearRegression().fit(model_df[x].values.reshape(-1,1), model_df[self.Y]).coef_[0]\n",
    "            betas.append(beta)\n",
    "            if beta < 0:\n",
    "                signs.append('neg')\n",
    "            else:\n",
    "                signs.append('pos')\n",
    "\n",
    "        self.feat_imp_df['lin_coef'] = betas\n",
    "        self.feat_imp_df['direction'] = signs\n",
    "        \n",
    "        self._get_feature_imp_cutoffs()\n",
    "\n",
    "\n",
    "    def _get_feature_imp_cutoffs(self):\n",
    "\n",
    "        cs = np.cumsum(self.feat_imp_df.imp.values)\n",
    "        \n",
    "        for cut in self.feat_imp_thresholds:\n",
    "            self.feat_imp_index[cut] = np.argmin((cs - cut)**2)\n",
    "            \n",
    "\n",
    "class ModelCVWrapper(object):\n",
    "    \n",
    "    def __init__(self, n_splits):\n",
    "        self.cv_summary_df = None\n",
    "        self.model_type = None\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "        \n",
    "    def _get_default_grid(self):\n",
    "        \n",
    "        if self.model_type == 'classification':\n",
    "            rf_grid = {'n_estimators':[200,500], 'max_depth':[5,10], 'criterion':['entropy']}\n",
    "            gbdt_grid = {'n_estimators':[100,200,500],'max_depth':[5,7], \n",
    "                    'learning_rate':[0.05,0.1]}\n",
    "            grid_dict = {RandomForestClassifier():rf_grid, GradientBoostingClassifier(): gbdt_grid}            \n",
    "        else:\n",
    "            rf_grid = {'n_estimators':[200,500], 'max_depth':[5,10], 'criterion':['mse','mae']}\n",
    "            gbdt_grid = {'n_estimators':[100,200,500],'max_depth':[5,7], 'loss':['ls'], 'alpha':[0.5],\n",
    "                    'learning_rate':[0.05,0.1]}\n",
    "            grid_dict = {RandomForestRegressor():rf_grid, GradientBoostingRegressor(): gbdt_grid}\n",
    "            \n",
    "        return grid_dict\n",
    "        \n",
    "    def get_model_cv(self, train_df, test_df, Y, feature_importance, thresholds,\n",
    "                          grid_dict=None, print_status=True):\n",
    "        '''\n",
    "        Inputs:\n",
    "        train_df is the training data, CV will be applied to it\n",
    "        test_df is the out of sample \n",
    "        grid_dict has the format of : {sklearn.model_type: parameter_grid}\n",
    "        feature_importance is a FeatureImportanceSummary object\n",
    "        thresholds -> the feature importance thresholds you want to test. \n",
    "\n",
    "        Performs cross-validation for each model type, on different subsets of model features\n",
    "        \n",
    "        Automatically determines regression or classification based on target value\n",
    "    \n",
    "        Returns a dataframe of cross-validation results\n",
    "        '''\n",
    "        \n",
    "        #Determine if Y is a continuous or discrete variable\n",
    "        num_distinct_targets = len(model_df['avg_consumption'].value_counts())\n",
    "            \n",
    "        if num_distinct_targets <= 10:\n",
    "            self.model_type = 'classification'\n",
    "        else:\n",
    "            self.model_type = 'regression'\n",
    "        \n",
    "        if grid_dict is None:\n",
    "            grid_dict = self._get_default_grid()\n",
    "\n",
    "\n",
    "        kf = KFold(n_splits=self.n_splits, random_state=10, shuffle=False)\n",
    "\n",
    "        #Get the index and create a list of features at a certain feat imp threshold\n",
    "        ordered_x = feature_importance.feat_imp_df.x.values\n",
    "        \n",
    "        subsets = []\n",
    "        for thresh in thresholds:\n",
    "            subsets.append(ordered_x[0:feature_importance.feat_imp_index[thresh]])\n",
    "                \n",
    "    \n",
    "        results = []\n",
    "        for i, subset in enumerate(subsets):\n",
    "            for model in grid_dict:\n",
    "                \n",
    "                if print_status:\n",
    "                    print('Running Treshold {}'.format(thresholds[i]))\n",
    "                \n",
    "                \n",
    "                #Run a grid search CV on the particular classifier\n",
    "                mod = GridSearchCV(model, grid_dict[model], cv=kf, scoring='neg_mean_squared_error')\n",
    "                mod.fit(train_df[subset], train_df[Y])\n",
    "        \n",
    "                #Get Mean-Squared Error on ttest set\n",
    "                test_err = ((mod.best_estimator_.predict(test_df[subset]) - test_df[Y])**2).mean()\n",
    "            \n",
    "                #Append results to a DF\n",
    "                results.append((type(model).__name__, len(subset), mod.best_score_, str(mod.best_params_), test_err))\n",
    "\n",
    "        cv_summary_df = pd.DataFrame(results, columns=['algo_string','subset_index','cv_score','params','test_score'])\n",
    "        cv_summary_df = cv_summary_df.sort_values(by=['cv_score'], ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        return cv_summary_df\n",
    "\n",
    "        \n",
    "    def increment_cv(self, train_df, test_df, Y, feature_importance, thresholds,\n",
    "                       grid_dict=None):\n",
    "        '''\n",
    "        Adds more test cases to cv - need to think about this more\n",
    "        '''\n",
    "        new_summary_df = self.get_model_cv(train_df, test_df, Y, feature_importance, thresholds)\n",
    "\n",
    "        self.cv_summary_df = pd.concat([self.cv_summary_df, new_summary_df])\n",
    "        self.cv_summary_df = self.cv_summary_df.sort_values(by=['cv_score'], ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        self.get_best_model(train_df, test_df, Y, feature_importance)\n",
    "\n",
    "        \n",
    "    def get_best_model(self, train_df, test_df, Y, feature_importance, thresholds = [0.8, 0.9, 0.95, 0.99],\n",
    "                       grid_dict=None):\n",
    "        '''\n",
    "        Fit a model to the best cv results\n",
    "        '''\n",
    "        \n",
    "        if self.cv_summary_df is None:\n",
    "            self.cv_summary_df = self.get_model_cv(train_df, test_df, Y, feature_importance, thresholds, grid_dict)\n",
    "    \n",
    "        #Get best model\n",
    "        best_params = ast.literal_eval(self.cv_summary_df.loc[0]['params'])\n",
    "\n",
    "        best_subset_index = self.cv_summary_df.loc[0]['subset_index']\n",
    "        self.best_subset = feature_importance.feat_imp_df.x.values[0:best_subset_index]\n",
    "        \n",
    "        #This converts the class string back a class, and uses the best parameters found in CV\n",
    "        self.best_model = eval(self.cv_summary_df.loc[0]['algo_string'])(**best_params) \n",
    "        self.best_model.fit(train_df[self.best_subset], train_df[Y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_june = '/Users/briandalessandro/Documents/CrossBoundary/E4I-Datasets/June_2019_DataShare/'\n",
    "model_df = pd.read_csv(data_dir_june + 'training_all_in.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a ranked list of features by their feature importance. Use the convenience class created for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = FeatureImportanceSummary(model_df, non_model_features, 'avg_consumption')\n",
    "fi.get_feature_importance_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the top K features that contain 80% of the normalized information gain (the importance metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>imp</th>\n",
       "      <th>lin_coef</th>\n",
       "      <th>direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tariff</td>\n",
       "      <td>0.400476</td>\n",
       "      <td>-0.094498</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non_self_generated_electricity_monthly_consump...</td>\n",
       "      <td>0.055983</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>years_in_community</td>\n",
       "      <td>0.048476</td>\n",
       "      <td>-0.002154</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phone</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x       imp  lin_coef  \\\n",
       "0                                             tariff  0.400476 -0.094498   \n",
       "1  non_self_generated_electricity_monthly_consump...  0.055983  0.000003   \n",
       "2                                 years_in_community  0.048476 -0.002154   \n",
       "3                                             energy  0.033691  0.004043   \n",
       "4                                              phone  0.020734  0.003265   \n",
       "\n",
       "  direction  \n",
       "0       neg  \n",
       "1       pos  \n",
       "2       neg  \n",
       "3       pos  \n",
       "4       pos  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.feat_imp_df.loc[0:fi.feat_imp_index[0.8]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(model_df, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a best performing regression model using grid search and cross-validation (this can take some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Treshold 0.8\n",
      "Running Treshold 0.9\n"
     ]
    }
   ],
   "source": [
    "reg_cv = ModelCVWrapper(5)\n",
    "\n",
    "rf_grid = {'n_estimators':[100,200], 'max_depth':[5,10], 'criterion':['mse']}\n",
    "grid_dict = {RandomForestRegressor():rf_grid}\n",
    "\n",
    "\n",
    "reg_cv.get_best_model(train_df, test_df, 'avg_consumption', fi, [0.8,0.9], grid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at results from the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_string</th>\n",
       "      <th>subset_index</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>params</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.042120</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 5, 'n_estima...</td>\n",
       "      <td>0.015160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.042219</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 5, 'n_estima...</td>\n",
       "      <td>0.015805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             algo_string  subset_index  cv_score  \\\n",
       "0  RandomForestRegressor            26 -0.042120   \n",
       "1  RandomForestRegressor            49 -0.042219   \n",
       "\n",
       "                                              params  test_score  \n",
       "0  {'criterion': 'mse', 'max_depth': 5, 'n_estima...    0.015160  \n",
       "1  {'criterion': 'mse', 'max_depth': 5, 'n_estima...    0.015805  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_cv.cv_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do an evaluation summary of the best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define this as a classification problem and get a best performing classification model using grid search and cross-validation (this can take some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
