{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Similarity-Based Recommendation Systems\n",
    "\n",
    "In course 3 we learned about classification and methods of supervised learning. In ths course we will discuss the use of a recommendation system and give a recap of this series of courses and what we have learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting up the Data\n",
    "\n",
    "This dataset is a series of reviews and ratings of Digital Video Games from Amazon. \n",
    "https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "path = \"/Users/Cheedo/Documents/wMF/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to set up our data in the same way we did in Course 3. Based on Ratings and Votes we will make recomendations based on a selected Game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(path, 'rt', encoding=\"utf8\")\n",
    "\n",
    "header = f.readline()\n",
    "header = header.strip().split('\\t')\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for line in f:\n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what a typical entry will look like in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'marketplace': 'US',\n",
       " 'customer_id': '21269168',\n",
       " 'review_id': 'RSH1OZ87OYK92',\n",
       " 'product_id': 'B013PURRZW',\n",
       " 'product_parent': '603406193',\n",
       " 'product_title': 'Madden NFL 16 - Xbox One Digital Code',\n",
       " 'product_category': 'Digital_Video_Games',\n",
       " 'star_rating': 2,\n",
       " 'helpful_votes': 2,\n",
       " 'total_votes': 3,\n",
       " 'vine': 'N',\n",
       " 'verified_purchase': 'N',\n",
       " 'review_headline': 'A slight improvement from last year.',\n",
       " 'review_body': \"I keep buying madden every year hoping they get back to football. This years version is a little better than last years -- but that's not saying much.The game looks great. The only thing wrong with the animation, is the way the players are always tripping on each other.<br /><br />The gameplay is still slowed down by the bloated pre-play controls. What used to take two buttons is now a giant PITA to get done before an opponent snaps the ball or the play clock runs out.<br /><br />The turbo button is back, but the player movement is still slow and awkward. If you liked last years version, I'm guessing you'll like this too. I haven't had a chance to play anything other than training and a few online games, so I'm crossing my fingers and hoping the rest is better.<br /><br />The one thing I can recommend is NOT TO BUY THE MADDEN BUNDLE. The game comes as a download. So if you hate it, there's no trading it in at Gamestop.\",\n",
       " 'review_date': '2015-08-31'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Finding Similarities\n",
    "\n",
    "In Course 3 we learned how to take the above review and predict a star rating (or any other value) by using models which gave each word in a review a weight and predicted the rating based on the sum of those weights. Now we will learn the basic ideas behind how to make a Recommendation. The parts of our data we want to work with are \"Star Rating\", \"HelpFul Votes\", and \"Total Votes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "\n",
    "itemNames = {}\n",
    "\n",
    "for d in dataset:\n",
    "    user,item = d['customer_id'], d['product_id']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    itemNames[item] = d['product_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to find Similarities\n",
    "\n",
    "We need to set up our Jaccard function and a function to determine what is similar within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(iD, n):\n",
    "    similarities = []\n",
    "    users = usersPerItem[iD]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == iD: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a recommendation\n",
    "\n",
    "Our mostSimilar function above takes an input of a \"Product ID\" and a value n which is the number of similar Products we would like, then outputs a list of size n with the Poduct ID's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'marketplace': 'US',\n",
       " 'customer_id': '45765011',\n",
       " 'review_id': 'R3YOOS71KM5M9',\n",
       " 'product_id': 'B00DNHLFQA',\n",
       " 'product_parent': '951665344',\n",
       " 'product_title': 'Command & Conquer The Ultimate Collection [Instant Access]',\n",
       " 'product_category': 'Digital_Video_Games',\n",
       " 'star_rating': 5,\n",
       " 'helpful_votes': 0,\n",
       " 'total_votes': 0,\n",
       " 'vine': 'N',\n",
       " 'verified_purchase': 'Y',\n",
       " 'review_headline': 'Hail to the great Yuri!',\n",
       " 'review_body': 'If you are prepping for the end of the world this is one of those things that you should have installed on your-end-of-the-world-proof PC.  Hail to the great Yuri!',\n",
       " 'review_date': '2015-08-31'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B004774IPU'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = dataset[10]['product_id']\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sid Meier's Civilization V\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemNames[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01856763925729443, 'B00CYOHL48'),\n",
       " (0.014492753623188406, 'B0085O6NG8'),\n",
       " (0.009067357512953367, 'B00475AYUA'),\n",
       " (0.007462686567164179, 'B008ALU5KG'),\n",
       " (0.00741839762611276, 'B006ULENFG'),\n",
       " (0.006544502617801047, 'B00JLK6ULS'),\n",
       " (0.006462035541195477, 'B005OSTWWK'),\n",
       " (0.005594405594405594, 'B004UHSGUA'),\n",
       " (0.005412719891745603, 'B005HRZ29K'),\n",
       " (0.005119453924914676, 'B0085P7YGU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilar(query, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Sid Meier's Civilization V: Brave New World\",\n",
       " \"Sid Meier's Civilization V: Gods and Kings - PC\",\n",
       " 'Sid Meiers Civilization IV: The Complete Edition',\n",
       " 'XCOM: Enemy Unknown',\n",
       " 'Crusader Kings II [Download]',\n",
       " \"Sid Meier's Civilization: Beyond Earth\",\n",
       " \"Sid Meier's Civilization V Game of The Year Edition\",\n",
       " 'Just Cause 2',\n",
       " 'Deus Ex: Human Revolution - Standard Edition [Download]',\n",
       " 'Torchlight']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO Get a list of 10 most similar product names to our query defined above\n",
    "\n",
    "### Note we want PRODUCT NAMES here, not ID's\n",
    "\n",
    "[itemNames[x[\"TODO\"]] for x in mostSimilar(query, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in this example, we get 3 different instances of \"Sid Meier's Civilization V\". We aren't taking into account the fact that multiple digital games share the same beginning characters since they have extra downloadable content for the same game. This is good in basic recommendation systems as someone who bought the original query of \"Sid Meier's Civilization V\" is likely to be interested in extra content for the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Collaborative-Filtering-Based Rating Estimation\n",
    "\n",
    "We can also use the similarity-based recommender we developed above to make predictions about user's ratings. Although this is not an example of machine learning, it is a simple heuristic that can be used to estimate a user's future ratings based on their ratings in the past.\n",
    "\n",
    "Specifically, a user's rating for an item is assumed to be a weighted sum of their previous ratings, weighted by how similar the query item is to each of their previous purchases.\n",
    "\n",
    "We start by building a few more utility data structures to keep track of all of the reviews by each user and for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for d in dataset:\n",
    "    user,item = d['customer_id'], d['product_id']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8531262248076406"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO Calculate the mean rating of the entire dataset\n",
    "\n",
    "#Answer should be roughly 3.853..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have calculated the average rating of our dataset as a whole, we are going to implement a function which predicts Rating based on a user and an item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['product_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['star_rating'])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'marketplace': 'US',\n",
       " 'customer_id': '8926809',\n",
       " 'review_id': 'R3B3UHK1FO0ERS',\n",
       " 'product_id': 'B004774IPU',\n",
       " 'product_parent': '151985175',\n",
       " 'product_title': \"Sid Meier's Civilization V\",\n",
       " 'product_category': 'Digital_Video_Games',\n",
       " 'star_rating': 1,\n",
       " 'helpful_votes': 0,\n",
       " 'total_votes': 0,\n",
       " 'vine': 'N',\n",
       " 'verified_purchase': 'N',\n",
       " 'review_headline': \"I am still playing Civ 4 and love it. It's a shame because I'm ready for ...\",\n",
       " 'review_body': \"As has been written by so many others, I quickly lost interest in this game. I am still playing Civ 4 and love it. It's a shame because I'm ready for an expanded version of Civ 4 and have waited for about a decade for a better version of it. Civ 5 was not an evolution but a total rewrite and it lost all that was good in Civ 4. I really hope that when Civ 6 comes out they use Civ 4 as the starting point and forget Civ 5 ever happened. Failing that there is a place in the market for a strategy game that involves building a civilisation.\",\n",
       " 'review_date': '2015-08-31'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8531262248076406"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO Using the function defined above, calculate the predicted rating for the user at index [10]\n",
    "\n",
    "user,item = dataset[ \"TODO\" ]['customer_id'], dataset[ \"TODO\" ]['product_id']\n",
    "predictRating(user, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case our user hasn't rated any similar items, so our function defaults to returning the dataset Mean Rating. Let's try another example with a user who has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.305965957081731"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO Calculate the predicted rating for the user at index [12]\n",
    "\n",
    "#Answer should differ from the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluating Performance\n",
    "\n",
    "Lets start by defining out typical MSE function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of our model, we will need two things:\n",
    "1. A list of the average Rating (i.e. ratingMean)\n",
    "2. A list of our predicted ratings (i.e. ratings defined by our predictRating function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Define the two lists described above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will compare our two lists above with the actual star ratings in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.371535478415058 2.3705596136412614\n"
     ]
    }
   ],
   "source": [
    "labels = [d['star_rating'] for d in dataset]\n",
    "\n",
    "print(MSE(alwaysPredictMean, labels), MSE(cfPredictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the accuracy of our rating prediction model was _nearly identical_ (in terms of the MSE) than just predicting the mean rating. However note again that this is just a heuristic example, and the similarity function could be modified to change its predictions (e.g. by using a different function other than the Jaccard similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're all done!\n",
    "\n",
    "This week was an introduction to the basics of recomender systems. Next week we will go over Latent Factor Models and how to implement them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
